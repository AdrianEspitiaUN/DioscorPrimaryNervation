{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54618,"status":"ok","timestamp":1699563631179,"user":{"displayName":"Adrian David Espitia Bayona","userId":"05997984479881469707"},"user_tz":300},"id":"330S5Iyqso3L","outputId":"1c6f80a3-5b72-463f-a9d7-aeca57f02fe0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"330S5Iyqso3L"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":838,"status":"ok","timestamp":1699563673879,"user":{"displayName":"Adrian David Espitia Bayona","userId":"05997984479881469707"},"user_tz":300},"id":"ASO0WdHFswix","outputId":"f639b24c-f3b3-46a3-d8d6-c21bd46af208"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/few-shot-leaf-segmentation/notebooks\n"]}],"source":["%cd /content/drive/MyDrive/few-shot-leaf-segmentation/notebooks"],"id":"ASO0WdHFswix"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4867,"status":"ok","timestamp":1699375972570,"user":{"displayName":"Adrian David Espitia Bayona","userId":"05997984479881469707"},"user_tz":300},"id":"bMjZoR-rsd_0","outputId":"0e55df42-9a57-4229-ebcb-0b06c068f068"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting numpy==1.21.6 (from -r requirements.txt (line 1))\n","  Downloading numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Pillow==9.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (9.4.0)\n","Collecting scikit_image==0.19.2 (from -r requirements.txt (line 3))\n","  Downloading scikit_image-0.19.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scipy==1.7.3 (from -r requirements.txt (line 4))\n","  Downloading scipy-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: Ignored the following versions that require a different python version: 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.11.0+cu113 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.11.0+cu113\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -r requirements.txt"],"id":"bMjZoR-rsd_0"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":702,"status":"ok","timestamp":1699376378361,"user":{"displayName":"Adrian David Espitia Bayona","userId":"05997984479881469707"},"user_tz":300},"id":"UFJ3oJQmuaYq","outputId":"7717beed-5162-46e7-8bc1-f22c2e43d8f6"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/few-shot-leaf-segmentation/notebooks'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["os.getcwd()"],"id":"UFJ3oJQmuaYq"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9327,"status":"ok","timestamp":1699563689896,"user":{"displayName":"Adrian David Espitia Bayona","userId":"05997984479881469707"},"user_tz":300},"id":"drawn-workstation","outputId":"9cad01ec-1287-4589-9ea5-76c3e739a16c"},"outputs":[{"name":"stdout","output_type":"stream","text":["---------------------------\n"," GPU | Memory-usage    \n","---------------------------\n","  0  | 00003MiB / 40537MiB\n","---------------------------\n"," Device set to cuda:0\n","---------------------------\n"]}],"source":["import os, sys, glob, pdb, random, time\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import torch\n","from PIL import Image\n","from importlib import reload\n","from skimage import measure\n","\n","sys.path.append('../')\n","import models.BuildCNN as BuildCNN\n","import models.VeinGrower as VeinGrower\n","from utils.GetLowestGPU import GetLowestGPU\n","\n","if 'device' not in locals():\n","    device = torch.device(GetLowestGPU(verbose=2))"],"id":"drawn-workstation"},{"cell_type":"markdown","metadata":{"id":"guided-speech"},"source":["# Initialize grower"],"id":"guided-speech"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11113,"status":"ok","timestamp":1699563700967,"user":{"displayName":"Adrian David Espitia Bayona","userId":"05997984479881469707"},"user_tz":300},"id":"affiliated-search","outputId":"807a45ed-fb3f-4c1d-9328-a0edee82bc73"},"outputs":[{"name":"stdout","output_type":"stream","text":["loading cnn model...\n","initializing vein grower...\n"]}],"source":["# options\n","window_size = 128\n","loss = 'fl' # 'fl' 'bce'\n","weights_path = f'../weights/vein_grower_{loss}_{window_size}_best_val_model.save'\n","layers = layers = [3, 32, 32, 32, 32, 64, 128]\n","output_shape = [2, 3, 3]\n","output_activation = torch.nn.Softmax2d()\n","\n","# load CNN model\n","print('loading cnn model...')\n","reload(BuildCNN)\n","model = BuildCNN.CNN(\n","    window_size=window_size,\n","    layers=layers,\n","    output_shape=output_shape,\n","    output_activation=output_activation).to(device)\n","weights = torch.load(weights_path, map_location=device)\n","model.load_state_dict(weights)\n","model.eval()\n","\n","# initialize vein grower\n","print('initializing vein grower...')\n","reload(VeinGrower)\n","grower = VeinGrower.VeinGrower(\n","    window_size=window_size,\n","    model=model,\n","    device=device,\n","    verbose=True)"],"id":"affiliated-search"},{"cell_type":"markdown","metadata":{"id":"bc217957-5207-4f7d-8957-fa14b8d608cb"},"source":["# Grower inference"],"id":"bc217957-5207-4f7d-8957-fa14b8d608cb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"d9faef5d-e70c-431a-b8bb-eb844a219d42"},"outputs":[],"source":["# options\n","image_path = '../data/images/'\n","roi_path = '../data/leaf_preds/'\n","pred_path = f'../data/vein_{loss}_preds/'\n","prob_path = f'../data/vein_{loss}_probs/'\n","image_extension = 'jpeg'\n","roi_extension = 'png'\n","pred_extension = 'png'\n","prob_extension = 'png'\n","n_locs = 10000 # number of seed pixels\n","batch_size = 2048\n","threshold = None\n","post_process = True\n","max_number = 10 # number of images to segment, set to None for all images\n","verbose = True\n","save = False\n","show = True\n","fig_size = 15\n","\n","# get image paths\n","image_names = [os.path.basename(f) for f in glob.glob(image_path+'*'+image_extension) if '_bot' in f]\n","image_names.sort()\n","\n","# loop over all leaf images\n","for image_idx, image_name in enumerate(image_names):\n","\n","    # don't exceed maximum\n","    if max_number is not None:\n","        if image_idx >= max_number:\n","            break\n","\n","    # load image\n","    if verbose:\n","        print(f'Loading {image_name}...')\n","    image = np.array(Image.open(image_path + image_name), dtype=np.float32)/255\n","    if roi_path is not None:\n","        roi = np.array(Image.open(\n","            roi_path + image_name.replace(image_extension, roi_extension)), dtype=np.float32)/255\n","        roi = roi[:,:,0] > 0.5\n","    else:\n","        roi = None\n","\n","    # segment the venation\n","    t0 = time.time()\n","    prob, mask = grower.grow(\n","        image=image,\n","        roi=roi,\n","        start_locs=None,\n","        n_locs=n_locs,\n","        batch_size=batch_size,\n","        threshold=threshold,\n","        post_process=post_process)\n","    t1 = time.time()\n","    if verbose:\n","        print('Iteration completed in {0:1.2f} seconds'.format(t1-t0))\n","\n","    # get positive class\n","    prob = prob[0]\n","\n","    # save mask\n","    if save:\n","        if verbose:\n","            print('Saving mask...')\n","        save_mask = np.concatenate([mask[:,:,None], mask[:,:,None], mask[:,:,None]], axis=-1)\n","        pil_mask = Image.fromarray(np.uint8(255*save_mask))\n","        name = pred_path + image_name.replace(image_extension, pred_extension)\n","        pil_mask.save(name, quality=100, subsampling=0)\n","\n","    # save prob\n","    if save:\n","        if verbose:\n","            print('Saving prob...')\n","        prob = prob[0] if len(prob.shape) == 3 else prob\n","        save_prob = np.concatenate([prob[:,:,None], prob[:,:,None], prob[:,:,None]], axis=-1)\n","        pil_prob = Image.fromarray(np.uint8(255*save_prob))\n","        name = prob_path + image_name.replace(image_extension, prob_extension)\n","        pil_prob.save(name, quality=100, subsampling=0)\n","\n","    # plot overlay\n","    if show:\n","        if verbose:\n","            print('Plotting overlay...')\n","        image[mask] = [1, 0, 0]\n","        fig = plt.figure(figsize=(image.shape[1]/image.shape[0]*fig_size, fig_size))\n","        plt.imshow(image)\n","        plt.show()\n","\n","    if verbose:\n","        print()"],"id":"d9faef5d-e70c-431a-b8bb-eb844a219d42"},{"cell_type":"markdown","metadata":{"id":"bcb4ccda"},"source":["# Grower inference on dioscoreaceae"],"id":"bcb4ccda"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","output_embedded_package_id":"1f14974lOwbt39p3wS2CKdoVB7d96ODkz"},"id":"a7091072-0fbd-434e-901c-592cbc97c88e","outputId":"de037fb4-6f90-4f42-8db3-fe36a73aa803"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# options\n","image_path = '../data/images/graph/'\n","roi_path = '../data/leaf_preds/graph/'\n","pred_path = f'../data/vein_{loss}_preds/'\n","prob_path = f'../data/vein_{loss}_probs/'\n","image_extension = 'jpg'\n","roi_extension = 'png'\n","pred_extension = 'png'\n","prob_extension = 'png'\n","n_locs = 10000 # number of seed pixels\n","batch_size = 2048\n","threshold = None\n","post_process = True\n","max_number = 2 # number of images to segment, set to None for all images\n","verbose = True\n","save = True\n","show = True\n","fig_size = 15\n","\n","# get image paths\n","image_names = [os.path.basename(f) for f in glob.glob(image_path+'*'+image_extension) if '_bot' in f]\n","image_names.sort()\n","\n","print(image_names)\n","\n","# loop over all leaf images\n","for image_idx, image_name in enumerate(image_names):\n","    #if os.path.exists(prob_path + image_name.replace(image_extension, prob_extension)):\n","      #continue\n","    # don't exceed maximum\n","    if max_number is not None:\n","        if image_idx >= max_number:\n","            break\n","\n","    # load image\n","    if verbose:\n","        print(f'Loading {image_name}...')\n","    image = np.array(Image.open(image_path + image_name), dtype=np.float32)/255\n","    if roi_path is not None:\n","        roi = np.array(Image.open(\n","            roi_path + image_name.replace(image_extension, roi_extension)), dtype=np.float32)/255\n","        roi = roi[:,:,0] > 0.5\n","    else:\n","        roi = None\n","\n","    # segment the venation\n","    t0 = time.time()\n","    prob, mask = grower.grow(\n","        image=image,\n","        roi=roi,\n","        start_locs=None,\n","        n_locs=n_locs,\n","        batch_size=batch_size,\n","        threshold=threshold,\n","        post_process=post_process)\n","    t1 = time.time()\n","    if verbose:\n","        print('Iteration completed in {0:1.2f} seconds'.format(t1-t0))\n","\n","    # get positive class\n","    prob = prob[0]\n","\n","    # save mask\n","    if save:\n","        if verbose:\n","            print('Saving mask...')\n","        save_mask = np.concatenate([mask[:,:,None], mask[:,:,None], mask[:,:,None]], axis=-1)\n","        pil_mask = Image.fromarray(np.uint8(255*save_mask))\n","        name = pred_path + image_name.replace(image_extension, pred_extension)\n","        pil_mask.save(name, quality=100, subsampling=0)\n","\n","    # save prob\n","    if save:\n","        if verbose:\n","            print('Saving prob...')\n","        prob = prob[0] if len(prob.shape) == 3 else prob\n","        save_prob = np.concatenate([prob[:,:,None], prob[:,:,None], prob[:,:,None]], axis=-1)\n","        pil_prob = Image.fromarray(np.uint8(255*save_prob))\n","        name = prob_path + image_name.replace(image_extension, prob_extension)\n","        pil_prob.save(name, quality=100, subsampling=0)\n","\n","    # plot overlay\n","    if show:\n","        if verbose:\n","            print('Plotting overlay...')\n","        image[mask] = [1, 0, 0]\n","        cv2.imwrite('/content/drive/MyDrive/'+image_name,image)\n","        fig = plt.figure(figsize=(image.shape[1]/image.shape[0]*fig_size, fig_size))\n","        plt.imshow(image)\n","        plt.show()\n","\n","    if verbose:\n","        print()"],"id":"a7091072-0fbd-434e-901c-592cbc97c88e"},{"cell_type":"code","execution_count":null,"metadata":{"id":"db7ca37d-2a61-4e59-999f-e5290148b366"},"outputs":[],"source":["import cv2"],"id":"db7ca37d-2a61-4e59-999f-e5290148b366"}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"}},"nbformat":4,"nbformat_minor":5}